{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6e89298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "class IkedaMultiSampleLoop:\n",
    "    def __init__(self, sample_folder_path, bpm=160):\n",
    "        \"\"\"\n",
    "        Ryoji Ikeda-inspired IDM loop generator with multiple samples\n",
    "        \n",
    "        Parameters:\n",
    "        - sample_folder_path: folder containing your .wav samples\n",
    "        - bpm: tempo for the loop\n",
    "        \"\"\"\n",
    "        self.sample_folder = sample_folder_path\n",
    "        self.bpm = bpm\n",
    "        self.sample_rate = 44100\n",
    "        self.beat_duration = 60 / bpm  # seconds per beat\n",
    "        \n",
    "        # Load all samples from folder\n",
    "        self.samples = self.load_all_samples(sample_folder_path)\n",
    "        print(f\"Loaded {len(self.samples)} samples\")\n",
    "        \n",
    "        # Categorize samples by characteristics\n",
    "        self.categorized_samples = self.categorize_samples()\n",
    "    \n",
    "    def load_all_samples(self, folder_path):\n",
    "        \"\"\"Load all .wav files from a folder\"\"\"\n",
    "        samples = {}\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith('.wav'):\n",
    "                filepath = os.path.join(folder_path, filename)\n",
    "                try:\n",
    "                    audio, sr = librosa.load(filepath, sr=self.sample_rate)\n",
    "                    \n",
    "                    # Ensure samples are short (trim if needed)\n",
    "                    if len(audio) > int(self.sample_rate * 0.3):  # 300ms max\n",
    "                        audio = audio[:int(self.sample_rate * 0.3)]\n",
    "                    \n",
    "                    # Normalize\n",
    "                    if np.max(np.abs(audio)) > 0:\n",
    "                        audio = audio / np.max(np.abs(audio)) * 0.8\n",
    "                    \n",
    "                    samples[filename] = {\n",
    "                        'audio': audio,\n",
    "                        'length': len(audio),\n",
    "                        'duration': len(audio) / sr,\n",
    "                        'filename': filename,\n",
    "                        'pitch': self.estimate_pitch(audio),\n",
    "                        'energy': np.mean(np.abs(audio))\n",
    "                    }\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {filename}: {e}\")\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def estimate_pitch(self, audio):\n",
    "        \"\"\"Simple pitch estimation for categorization\"\"\"\n",
    "        try:\n",
    "            if len(audio) > 2048:\n",
    "                freqs = np.fft.rfftfreq(len(audio), 1/self.sample_rate)\n",
    "                fft = np.abs(np.fft.rfft(audio))\n",
    "                if len(fft) > 0:\n",
    "                    dominant_freq = freqs[np.argmax(fft[1:]) + 1]\n",
    "                    return dominant_freq\n",
    "        except:\n",
    "            pass\n",
    "        return 1000  # Default\n",
    "    \n",
    "    def categorize_samples(self):\n",
    "        \"\"\"Categorize samples by their sonic characteristics\"\"\"\n",
    "        categories = {\n",
    "            'high_click': [],    # High frequency, short\n",
    "            'low_thud': [],      # Low frequency\n",
    "            'mid_punch': [],     # Mid-range\n",
    "            'noise': [],         # Noise-based\n",
    "            'tonal': [],         # Tonally rich\n",
    "            'metallic': [],      # Metallic character\n",
    "            'glitch': []         # Digital artifacts\n",
    "        }\n",
    "        \n",
    "        for name, sample in self.samples.items():\n",
    "            pitch = sample['pitch']\n",
    "            energy = sample['energy']\n",
    "            duration = sample['duration']\n",
    "            \n",
    "            # Categorization logic\n",
    "            if pitch > 3000 and duration < 0.05:\n",
    "                categories['high_click'].append(name)\n",
    "            elif pitch < 200:\n",
    "                categories['low_thud'].append(name)\n",
    "            elif 'noise' in name.lower() or 'hiss' in name.lower():\n",
    "                categories['noise'].append(name)\n",
    "            elif 'metal' in name.lower() or 'ting' in name.lower():\n",
    "                categories['metallic'].append(name)\n",
    "            elif pitch > 1000 and pitch < 3000:\n",
    "                categories['mid_punch'].append(name)\n",
    "            elif 'glitch' in name.lower() or 'error' in name.lower():\n",
    "                categories['glitch'].append(name)\n",
    "            else:\n",
    "                categories['tonal'].append(name)\n",
    "        \n",
    "        # Fill empty categories\n",
    "        all_samples = list(self.samples.keys())\n",
    "        for cat, samples in categories.items():\n",
    "            if len(samples) == 0:\n",
    "                categories[cat] = all_samples.copy()\n",
    "        \n",
    "        return categories\n",
    "    \n",
    "    def get_sample_by_category(self, category, pattern_position):\n",
    "        \"\"\"Get a sample from a specific category with some variation logic\"\"\"\n",
    "        available = self.categorized_samples.get(category, [])\n",
    "        if not available:\n",
    "            available = list(self.samples.keys())\n",
    "        \n",
    "        # Weight recent samples less to avoid repetition\n",
    "        if hasattr(self, 'recent_samples'):\n",
    "            weights = [0.5 if s in self.recent_samples[-3:] else 1.0 \n",
    "                      for s in available]\n",
    "            # Normalize weights\n",
    "            weights = np.array(weights) / np.sum(weights)\n",
    "            selected = np.random.choice(available, p=weights)\n",
    "        else:\n",
    "            selected = random.choice(available)\n",
    "        \n",
    "        # Track recent samples\n",
    "        if not hasattr(self, 'recent_samples'):\n",
    "            self.recent_samples = []\n",
    "        self.recent_samples.append(selected)\n",
    "        if len(self.recent_samples) > 10:\n",
    "            self.recent_samples.pop(0)\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def create_idm_pattern(self, bars=4, subdivision=16):\n",
    "        \"\"\"\n",
    "        Create an IDM-style rhythmic pattern with sample assignments\n",
    "        Returns pattern with (velocity, category) tuples\n",
    "        \"\"\"\n",
    "        pattern_length = bars * subdivision\n",
    "        pattern = []\n",
    "        \n",
    "        for i in range(pattern_length):\n",
    "            bar_pos = i % 16\n",
    "            beat_in_bar = bar_pos // 4\n",
    "            \n",
    "            # Determine sample category based on position\n",
    "            if bar_pos == 0:  # Downbeat\n",
    "                category = random.choice(['low_thud', 'mid_punch'])\n",
    "                velocity = 1.0\n",
    "            elif bar_pos in [4, 8, 12]:  # Other strong beats\n",
    "                category = random.choice(['mid_punch', 'tonal'])\n",
    "                velocity = 0.9\n",
    "            elif bar_pos % 2 == 1:  # Offbeats\n",
    "                category = random.choice(['high_click', 'metallic'])\n",
    "                velocity = 0.7\n",
    "            elif bar_pos in [2, 6, 10, 14]:  # Upbeats\n",
    "                category = random.choice(['high_click', 'glitch'])\n",
    "                velocity = 0.8\n",
    "            else:\n",
    "                # Fill positions\n",
    "                if random.random() > 0.6:\n",
    "                    category = random.choice(list(self.categorized_samples.keys()))\n",
    "                    velocity = random.uniform(0.3, 0.6)\n",
    "                else:\n",
    "                    category = None\n",
    "                    velocity = 0\n",
    "            \n",
    "            # Add occasional bursts\n",
    "            if random.random() > 0.95:  # 5% chance of fill\n",
    "                fill_length = random.randint(3, 6)\n",
    "                for j in range(min(fill_length, pattern_length - i)):\n",
    "                    pattern.append(('glitch', random.uniform(0.4, 0.8)))\n",
    "                i += fill_length - 1\n",
    "                continue\n",
    "            \n",
    "            pattern.append((category, velocity))\n",
    "        \n",
    "        return pattern\n",
    "    \n",
    "    def apply_sample_processing(self, sample_audio, pattern_position, velocity):\n",
    "        \"\"\"Apply processing to individual samples\"\"\"\n",
    "        processed = sample_audio.copy()\n",
    "        \n",
    "        # 1. Velocity-based gain\n",
    "        processed = processed * velocity\n",
    "        \n",
    "        # 2. Pitch shifting based on position\n",
    "        if random.random() > 0.7:\n",
    "            pitch_shift = random.choice([-12, -7, 0, 5, 7, 12])\n",
    "            if pitch_shift != 0:\n",
    "                try:\n",
    "                    processed = librosa.effects.pitch_shift(\n",
    "                        processed, \n",
    "                        sr=self.sample_rate, \n",
    "                        n_steps=pitch_shift\n",
    "                    )\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # 3. Reverse sometimes\n",
    "        if random.random() > 0.9:\n",
    "            processed = processed[::-1]\n",
    "        \n",
    "        # 4. Bitcrush occasionally\n",
    "        if random.random() > 0.8:\n",
    "            bits = random.choice([4, 8, 12])\n",
    "            processed = np.round(processed * (2**bits - 1)) / (2**bits - 1)\n",
    "        \n",
    "        # 5. Time stretch (micro)\n",
    "        if random.random() > 0.95:\n",
    "            stretch = random.uniform(0.5, 1.5)\n",
    "            if len(processed) > 100:\n",
    "                try:\n",
    "                    processed = librosa.effects.time_stretch(processed, rate=stretch)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # 6. Add digital noise\n",
    "        if random.random() > 0.9:\n",
    "            noise = np.random.normal(0, 0.02 * velocity, len(processed))\n",
    "            processed = processed + noise\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    def create_multi_sample_loop(self, bars=4, output_path=\"ikeda_multisample_loop.wav\"):\n",
    "        \"\"\"\n",
    "        Generate a 4-bar loop using multiple samples\n",
    "        \"\"\"\n",
    "        subdivision = 16  # 16th notes\n",
    "        pattern = self.create_idm_pattern(bars, subdivision)\n",
    "        \n",
    "        # Reset recent samples tracking\n",
    "        self.recent_samples = []\n",
    "        \n",
    "        # Calculate timing\n",
    "        sixteenth_duration = self.beat_duration / 4\n",
    "        total_duration = bars * 4 * self.beat_duration\n",
    "        total_samples = int(total_duration * self.sample_rate)\n",
    "        \n",
    "        # Create empty audio buffer\n",
    "        loop_audio = np.zeros(total_samples)\n",
    "        \n",
    "        # Track sample usage for reporting\n",
    "        sample_usage = defaultdict(int)\n",
    "        \n",
    "        # Place samples according to pattern\n",
    "        for i, (category, velocity) in enumerate(pattern):\n",
    "            if velocity > 0 and category:\n",
    "                # Get appropriate sample\n",
    "                sample_name = self.get_sample_by_category(category, i)\n",
    "                sample_usage[sample_name] += 1\n",
    "                \n",
    "                sample_data = self.samples[sample_name]\n",
    "                base_audio = sample_data['audio']\n",
    "                \n",
    "                # Apply processing\n",
    "                processed_click = self.apply_sample_processing(base_audio, i, velocity)\n",
    "                \n",
    "                # Calculate start position\n",
    "                start_time = i * sixteenth_duration\n",
    "                start_sample = int(start_time * self.sample_rate)\n",
    "                \n",
    "                # Add timing humanization (micro-variations)\n",
    "                timing_offset = random.randint(-5, 5)\n",
    "                actual_start = max(0, start_sample + timing_offset)\n",
    "                \n",
    "                # Add to loop\n",
    "                end_pos = min(len(loop_audio), actual_start + len(processed_click))\n",
    "                click_len = end_pos - actual_start\n",
    "                \n",
    "                if click_len > 0:\n",
    "                    loop_audio[actual_start:actual_start + click_len] += processed_click[:click_len]\n",
    "        \n",
    "        # Normalize to prevent clipping\n",
    "        peak = np.max(np.abs(loop_audio))\n",
    "        if peak > 0:\n",
    "            loop_audio = loop_audio / peak * 0.8\n",
    "        \n",
    "        # Save the loop\n",
    "        sf.write(output_path, loop_audio, self.sample_rate)\n",
    "        \n",
    "        # Print sample usage statistics\n",
    "        print(f\"\\n=== Loop Generation Complete ===\")\n",
    "        print(f\"BPM: {self.bpm}, Bars: {bars}\")\n",
    "        print(f\"Total samples used: {sum(sample_usage.values())}\")\n",
    "        print(f\"Unique samples used: {len(sample_usage)}\")\n",
    "        print(f\"\\nSample usage breakdown:\")\n",
    "        for sample, count in sorted(sample_usage.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "            print(f\"  {sample}: {count} hits\")\n",
    "        \n",
    "        return loop_audio, pattern, sample_usage\n",
    "    \n",
    "    def create_layered_loop(self, bars=4, layers=3, output_path=\"layered_loop.wav\"):\n",
    "        \"\"\"Create a multi-layered loop with different sample sets per layer\"\"\"\n",
    "        all_layers = []\n",
    "        \n",
    "        for layer in range(layers):\n",
    "            print(f\"\\nGenerating layer {layer + 1}/{layers}\")\n",
    "            \n",
    "            # Different parameters per layer\n",
    "            if layer == 0:  # Base layer\n",
    "                # Focus on low frequencies\n",
    "                self.categorized_samples = {k: v for k, v in self.categorized_samples.items() \n",
    "                                          if k in ['low_thud', 'mid_punch']}\n",
    "                layer_audio, _, _ = self.create_multi_sample_loop(bars, f\"layer_{layer}.wav\")\n",
    "                \n",
    "            elif layer == 1:  # Mid layer\n",
    "                # Focus on mid/high frequencies\n",
    "                self.categorized_samples = {k: v for k, v in self.categorized_samples.items() \n",
    "                                          if k in ['high_click', 'metallic', 'tonal']}\n",
    "                layer_audio, _, _ = self.create_multi_sample_loop(bars, f\"layer_{layer}.wav\")\n",
    "                \n",
    "            else:  # Top layer (glitch/effects)\n",
    "                # Only glitch and noise\n",
    "                self.categorized_samples = {k: v for k, v in self.categorized_samples.items() \n",
    "                                          if k in ['glitch', 'noise']}\n",
    "                layer_audio, _, _ = self.create_multi_sample_loop(bars, f\"layer_{layer}.wav\")\n",
    "            \n",
    "            all_layers.append(layer_audio)\n",
    "        \n",
    "        # Mix layers with different volumes\n",
    "        mixed = np.zeros_like(all_layers[0])\n",
    "        layer_volumes = [0.8, 0.6, 0.4]  # Base louder, top layers quieter\n",
    "        \n",
    "        for i, layer in enumerate(all_layers):\n",
    "            if len(layer) > len(mixed):\n",
    "                layer = layer[:len(mixed)]\n",
    "            mixed[:len(layer)] += layer[:len(mixed)] * layer_volumes[i]\n",
    "        \n",
    "        # Normalize\n",
    "        peak = np.max(np.abs(mixed))\n",
    "        if peak > 0:\n",
    "            mixed = mixed / peak * 0.8\n",
    "        \n",
    "        sf.write(output_path, mixed, self.sample_rate)\n",
    "        print(f\"\\nLayered loop saved to: {output_path}\")\n",
    "        \n",
    "        return mixed\n",
    "    \n",
    "    def export_sample_sheet(self, pattern, sample_usage, output_file=\"pattern_report.txt\"):\n",
    "        \"\"\"Export a text report of the pattern and sample usage\"\"\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(f\"Ryoji Ikeda-style IDM Loop Pattern\\n\")\n",
    "            f.write(f\"BPM: {self.bpm}\\n\")\n",
    "            f.write(f\"Time Signature: 4/4\\n\")\n",
    "            f.write(f\"Bars: {len(pattern)//16}\\n\\n\")\n",
    "            \n",
    "            f.write(\"PATTERN GRID:\\n\")\n",
    "            f.write(\"Pos | Cat       | Vel | Sample\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            \n",
    "            for i, (category, velocity) in enumerate(pattern):\n",
    "                if i % 16 == 0:\n",
    "                    f.write(f\"\\nBAR {i//16 + 1}:\\n\")\n",
    "                \n",
    "                if velocity > 0:\n",
    "                    # Find which sample would be used here\n",
    "                    sample_name = self.get_sample_by_category(category, i) if category else \"None\"\n",
    "                    f.write(f\"{i:3d} | {category or 'None':10} | {velocity:.2f} | {sample_name[:20]}\\n\")\n",
    "            \n",
    "            f.write(\"\\n\\nSAMPLE USAGE STATISTICS:\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "            for sample, count in sorted(sample_usage.items(), key=lambda x: x[1], reverse=True):\n",
    "                f.write(f\"{sample}: {count} hits\\n\")\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8efe05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 13 samples\n",
      "\n",
      "=== Loop Generation Complete ===\n",
      "BPM: 170, Bars: 4\n",
      "Total samples used: 74\n",
      "Unique samples used: 13\n",
      "\n",
      "Sample usage breakdown:\n",
      "  d3.wav: 11 hits\n",
      "  jalastram_snare_05.wav: 9 hits\n",
      "  test_kick_74.wav: 8 hits\n",
      "  test_kick_64.wav: 7 hits\n",
      "  test_kick_33.wav: 7 hits\n",
      "  test_kick_100.wav: 7 hits\n",
      "  test_kick_18.wav: 5 hits\n",
      "  pulse.wav: 5 hits\n",
      "  test_kick_53.wav: 4 hits\n",
      "  test_kick_3.wav: 4 hits\n",
      "\n",
      "Generating layer 1/3\n",
      "\n",
      "=== Loop Generation Complete ===\n",
      "BPM: 170, Bars: 4\n",
      "Total samples used: 77\n",
      "Unique samples used: 13\n",
      "\n",
      "Sample usage breakdown:\n",
      "  d3.wav: 11 hits\n",
      "  test_kick_3.wav: 8 hits\n",
      "  test_kick_74.wav: 7 hits\n",
      "  Kick_Low_Tone_One_Shot.wav: 7 hits\n",
      "  test_kick_125.wav: 6 hits\n",
      "  test_kick_33.wav: 6 hits\n",
      "  shhhhhh1.wav: 6 hits\n",
      "  jalastram_snare_05.wav: 5 hits\n",
      "  test_kick_18.wav: 5 hits\n",
      "  pulse.wav: 5 hits\n",
      "\n",
      "Generating layer 2/3\n",
      "\n",
      "=== Loop Generation Complete ===\n",
      "BPM: 170, Bars: 4\n",
      "Total samples used: 79\n",
      "Unique samples used: 13\n",
      "\n",
      "Sample usage breakdown:\n",
      "  d3.wav: 8 hits\n",
      "  test_kick_125.wav: 8 hits\n",
      "  shhhhhh1.wav: 8 hits\n",
      "  jalastram_snare_05.wav: 7 hits\n",
      "  test_kick_3.wav: 7 hits\n",
      "  test_kick_18.wav: 7 hits\n",
      "  test_kick_74.wav: 7 hits\n",
      "  Kick_Low_Tone_One_Shot.wav: 7 hits\n",
      "  test_kick_53.wav: 6 hits\n",
      "  pulse.wav: 5 hits\n",
      "\n",
      "Generating layer 3/3\n",
      "\n",
      "=== Loop Generation Complete ===\n",
      "BPM: 170, Bars: 4\n",
      "Total samples used: 71\n",
      "Unique samples used: 13\n",
      "\n",
      "Sample usage breakdown:\n",
      "  test_kick_18.wav: 8 hits\n",
      "  test_kick_33.wav: 8 hits\n",
      "  test_kick_125.wav: 7 hits\n",
      "  pulse.wav: 7 hits\n",
      "  Kick_Low_Tone_One_Shot.wav: 6 hits\n",
      "  test_kick_100.wav: 6 hits\n",
      "  jalastram_snare_05.wav: 6 hits\n",
      "  d3.wav: 6 hits\n",
      "  test_kick_74.wav: 4 hits\n",
      "  test_kick_64.wav: 4 hits\n",
      "\n",
      "Layered loop saved to: test1/ikeda_idm_loop_170_bpm_complex_layered_loop.wav\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "\n",
    "bpm = 170\n",
    "output_folder = 'test1'\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize with folder containing your samples\n",
    "    generator = IkedaMultiSampleLoop(\n",
    "        sample_folder_path=\"sound\",\n",
    "        bpm=bpm\n",
    "    )\n",
    "    \n",
    "    # Create a basic multi-sample loop\n",
    "    loop_audio, pattern, sample_usage = generator.create_multi_sample_loop(\n",
    "        bars=4,\n",
    "        output_path=f\"{output_folder}/ikeda_idm_loop_{bpm}_bpm_multi_sample_loop.wav\"\n",
    "    )\n",
    "    \n",
    "    # Export pattern report\n",
    "    generator.export_sample_sheet(pattern, sample_usage,f\"{output_folder}/ikeda_idm_loop_{bpm}_bpm_pattern_report.txt\")\n",
    "    \n",
    "    # Create a complex layered loop\n",
    "    layered_audio = generator.create_layered_loop(\n",
    "        bars=4,\n",
    "        layers=3,\n",
    "        output_path=f\"{output_folder}/ikeda_idm_loop_{bpm}_bpm_complex_layered_loop.wav\"\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc72d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10f82b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.24960321e-17,  3.41752350e-17,  2.51738126e-17, ...,\n",
       "        3.34534212e-13, -7.33910112e-13, -4.81372971e-12])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_granular_loop(sample_path, grain_size=500, overlap=0.99):\n",
    "    \"\"\"\n",
    "    Create granular texture from sample\n",
    "    \"\"\"\n",
    "    audio, sr = librosa.load(sample_path, sr=None)\n",
    "    \n",
    "    grain_samples = int(sr * grain_size / 1000)  # grain_size in ms\n",
    "    hop_samples = int(grain_samples * (1 - overlap))\n",
    "    \n",
    "    grains = []\n",
    "    for start in range(0, len(audio) - grain_samples, hop_samples):\n",
    "        grain = audio[start:start + grain_samples]\n",
    "        \n",
    "        # Apply window\n",
    "        window = np.hanning(len(grain))\n",
    "        grain = grain * window\n",
    "        \n",
    "        # Random pitch shift occasionally\n",
    "        if random.random() > 0.5:\n",
    "            grain = librosa.effects.pitch_shift(grain, sr=sr, n_steps=random.uniform(-24, 24))\n",
    "        \n",
    "        grains.append(grain)\n",
    "    \n",
    "    # Rearrange grains randomly\n",
    "    random.shuffle(grains)\n",
    "    \n",
    "    # Combine grains\n",
    "    output = np.concatenate(grains[:min(50, len(grains))])\n",
    "    \n",
    "    sf.write(\"granular_texture.wav\", output, sr)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "create_granular_loop(f\"idm_loop_{bpm}bpm.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86daca4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_env",
   "language": "python",
   "name": "virtual_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
